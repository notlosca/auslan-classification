{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eros norm:\n",
    "$$\n",
    "EROS(\\mathbf{A,B},w) = \\sum_{i=1}^n w_i\\cdot|<a_i,b_i>|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"tctodd/\"\n",
    "dirs = os.listdir(path=path)\n",
    "weeks = sorted([i for i in dirs if i != \".DS_Store\"])\n",
    "filenames = sorted(os.listdir(path+weeks[1]))\n",
    "\n",
    "data = []\n",
    "labels = dict()\n",
    "label_cnt = 0\n",
    "\n",
    "for w in weeks:\n",
    "    temp_path = path+w+\"/\"\n",
    "    filenames = sorted(os.listdir(temp_path))\n",
    "    for fn in filenames:\n",
    "        label = fn.split('.')[0][:-2]\n",
    "        \n",
    "        if label not in labels:\n",
    "            labels[label] = label_cnt\n",
    "            label_cnt += 1\n",
    "            \n",
    "        data.append({'label':labels[label], 'time_series':pd.read_csv(temp_path+fn, header=None, sep='\\t',).values})\n",
    "        \n",
    "df = pd.DataFrame(data, columns=['label', 'time_series'])\n",
    "\n",
    "#from sklearn.utils import shuffle\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 0\n",
    "\n",
    "# Shuffle the dataframe\n",
    "shuffled_df = sk.utils.shuffle(df, random_state=seed)\n",
    "\n",
    "'''\n",
    "from utils import extract_matrix\n",
    "# Create the matrix version\n",
    "shuffled_df.time_series = shuffled_df.time_series.apply(extract_matrix)\n",
    "shuffled_df[\"shape\"] = shuffled_df.time_series.apply(lambda x: x.shape)\n",
    "shuffled_df.head()\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(shuffled_df['time_series'], shuffled_df['label'], stratify=shuffled_df['label'], train_size=.7, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_S_matrix(ts_series:pd.Series) -> tuple[np.array, list]:\n",
    "    \"\"\"function to compute the S matrix of shape n x N (n = number of predictors, N = number of examples). \n",
    "    Such matrix will be used to compute\n",
    "    the weight vector needed by Eros norm\n",
    "\n",
    "    Args:\n",
    "        ts_series (pd.Series): Series containing the dataset of time series.\n",
    "        Each entry is a list of vectors. \n",
    "        Each vector is a component of the i-th time series\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.array, list]: returns the matrix S and the list of\n",
    "        right eigenvectors matrices computed for each time series\n",
    "    \"\"\"\n",
    "    s_matrix = np.zeros(shape=(len(ts_series), ts_series.iloc[0].shape[-1]))\n",
    "    v_list = [] # list of right eigenvector matrix\n",
    "    for i in range(len(ts_series)):\n",
    "        ts = ts_series.iloc[i] # time x predictors\n",
    "        \n",
    "        #The matrix S will be nxN where n is the predictor dimension and N is the number of time-series examples.\n",
    "        #Hence, we will use the transpose to compute the covariance matrix.\n",
    "        ts = ts.T # predictors x time\n",
    "        \n",
    "        # Compute the covariance matrix of the i-th example of the dataset\n",
    "        cov_ts = np.cov(ts)\n",
    "        # Compute the SVD of the covariance matrix\n",
    "        u, s, v_t = np.linalg.svd(cov_ts)\n",
    "        s_matrix[i] = s\n",
    "        v_list.append(v_t.T)\n",
    "    return s_matrix.T, v_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, v_list_train = compute_S_matrix(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_list_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 1795)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, v_list_test = compute_S_matrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight_vector(S:np.ndarray, aggregation:str='mean', algorithm:int=1) -> np.array:\n",
    "    \"\"\"compute the weight vector used in the computation of Eros norm\n",
    "\n",
    "    Args:\n",
    "        S (np.ndarray): matrix containing eigenvalues of each predictor\n",
    "        aggregation (str, optional): aggregation function to use. Defaults to 'mean'.\n",
    "        algorithm(int): choose the algorithm to use to compute weight vector.\n",
    "        - Algorithm 1: do not normalize rows of the S matrix. Perform directly the computation of w\n",
    "        - Algorithm 2: first normalize rows of the S matrix and then compute w.\n",
    "    Returns:\n",
    "        np.array: return the normalized weight vector\n",
    "    \"\"\"\n",
    "    n = S.shape[0] # number of predictors\n",
    "    if (algorithm == 2):\n",
    "        # first normalize each eigenvalues\n",
    "        #print(S[0])\n",
    "        S = S/np.sum(S, axis=-1).reshape(-1,1)\n",
    "        #print(S.shape)\n",
    "        #print(S[0])\n",
    "    if (aggregation == 'mean'):\n",
    "        w = np.mean(S, axis=-1)\n",
    "    elif (aggregation == 'min'):\n",
    "        w = np.min(S, axis=-1)\n",
    "    elif (aggregation == 'max'):\n",
    "        w = np.max(S, axis=-1)\n",
    "    return w/np.sum(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = compute_weight_vector(S, algorithm=2)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eros_norm(weight_vector:np.array, A:np.array, B:np.array):\n",
    "    \"\"\"compute eros norm\n",
    "\n",
    "    Args:\n",
    "        weight_vector (np.array): weight vector\n",
    "        A (np.array): time_series_1\n",
    "        B (np.array): time_series_2\n",
    "\n",
    "    Returns:\n",
    "        float: distance between the 2 time series. Bounded in (0,1]\n",
    "    \"\"\"\n",
    "    # since we want to use a_i and b_i which \n",
    "    # are the orthonormal column vectors of A and B,\n",
    "    # we decide to transpose A and B\n",
    "    A = A.T\n",
    "    B = B.T\n",
    "    \n",
    "    n = A.shape[0] # number of predictors\n",
    "    \n",
    "    eros = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        eros += weight_vector[i]*np.abs(np.dot(A[i], B[i]))\n",
    "    return eros\n",
    "\n",
    "def compute_kernel_matrix(num_examples:int, weight_vector:np.array, v_list:list[np.array]) -> np.array:\n",
    "    \"\"\"compute the kernel matrix to be used in PCA\n",
    "\n",
    "    Args:\n",
    "        num_examples (int): number of examples in the dataset\n",
    "        weight_vector (np.array): weight vector \n",
    "        v_t_list (list[np.array]): list of right eigenvector matrices\n",
    "\n",
    "    Returns:\n",
    "        np.array: kernel matrix with pairwise eros norm\n",
    "    \"\"\"\n",
    "    N = num_examples\n",
    "    K_eros = np.zeros(shape=(N,N))\n",
    "\n",
    "    for i in range(N):\n",
    "        j = 0\n",
    "        while (j <= i):\n",
    "            K_eros[i,j] = eros_norm(weight_vector, v_list[i], v_list[j])\n",
    "            if (i != j): \n",
    "                K_eros[j,i] = K_eros[i,j]\n",
    "            j += 1\n",
    "\n",
    "    # check whether the kernel matrix is positive semi definite (PSD) or not\n",
    "    is_psd = np.all(np.linalg.eigvals(K_eros) >= 0)\n",
    "    threshold = 1e-10\n",
    "    # if not PSD, add to the diagonal the minimal value among eigenvalues of K_eros\n",
    "    if is_psd == False:\n",
    "        delta = np.min(np.linalg.eigvals(K_eros))\n",
    "        delta_ary = [np.abs(delta) + threshold for _ in range(K_eros.shape[0])]\n",
    "        K_eros += np.diag(delta_ary)\n",
    "    is_psd = np.all(np.linalg.eigvals(K_eros) >= 0)\n",
    "    if is_psd == True:\n",
    "        print(\"now PSD\")\n",
    "        return K_eros\n",
    "    else:\n",
    "        print(\"not PSD\")\n",
    "    return K_eros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_PCA(num_examples:int, weight_vector:np.array, v_list:list[np.array]) -> tuple[np.ndarray, np.array]:\n",
    "    \"\"\"extract principal components in the feature space\n",
    "\n",
    "    Args:\n",
    "        num_examples (int): number of examples in the dataset\n",
    "        weight_vector (np.array): weight vector \n",
    "        v_t_list (list[np.array]): list of right eigenvector matrices\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.array]:\n",
    "        - K_eros matrix\n",
    "        - eigenvectors (principal components) of the feature space\n",
    "    \"\"\"\n",
    "    K_eros = compute_kernel_matrix(num_examples, weight_vector, v_list)\n",
    "    O = np.ones(shape=(num_examples,num_examples))\n",
    "    O *= 1/num_examples\n",
    "    K_eros_mc = K_eros - O@K_eros - K_eros@O + O@K_eros@O # K_eros mean centered\n",
    "    eig_vals, eig_vecs = np.linalg.eig(K_eros_mc)\n",
    "    return K_eros, eig_vecs, eig_vals\n",
    "\n",
    "\n",
    "def compute_test_kernel_matrix(num_training_examples:int, num_test_examples:int, weight_vector:np.array, v_list_train:list[np.array], v_list_test:list[np.array]) -> np.array:\n",
    "    \"\"\"compute the K eros test kernel matrix used to project test data\n",
    "\n",
    "    Args:\n",
    "        num_examples_train (int): number of examples in the training dataset\n",
    "        num_examples_test (int): number of examples in the test dataset\n",
    "        weight_vector (np.array): weight vector \n",
    "        v_list_train (list[np.array]): list of right eigenvector matrices of the training dataset\n",
    "        v_list_test (list[np.array]): list of right eigenvector matrices of the test dataset\n",
    "\n",
    "    Returns:\n",
    "        np.array: kernel matrix with pairwise eros norm\n",
    "    \"\"\"\n",
    "    N_train = num_training_examples\n",
    "    N_test = num_test_examples\n",
    "    K_eros_test = np.zeros(shape=(N_test,N_train))\n",
    "\n",
    "    for i in range(N_test):\n",
    "        for j in range(N_train):\n",
    "            K_eros_test[i,j] = eros_norm(weight_vector, v_list_test[i], v_list_train[j])\n",
    "    return K_eros_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now PSD\n"
     ]
    }
   ],
   "source": [
    "#K_eros_train = compute_kernel_matrix(len(X_train), weight_vector=w, v_list=v_list_train)\n",
    "\n",
    "# V column vectors, use v[:,i] to select the corresponding eigenvector\n",
    "K_eros_train, V, eig_vals = perform_PCA(len(X_train), weight_vector=w, v_list=v_list_train)\n",
    "\n",
    "K_eros_test = compute_test_kernel_matrix(len(X_train), len(X_test), w, v_list_train, v_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.999917569731185e-11"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.linalg.eigvals(K_eros_train) >= 0)\n",
    "delta = min(np.linalg.eigvals(K_eros_train))\n",
    "delta_I = np.diag(np.array([np.abs(delta) for _ in range(len(K_eros_train))]))\n",
    "np.all(np.linalg.eigvals(K_eros_train) >= 0)\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test = len(X_test)\n",
    "N_train = len(X_train)\n",
    "O_test = np.ones(shape=(N_test, N_train))*(1/N_train)\n",
    "O_train = np.ones(shape=(N_train, N_train))*(1/N_train)\n",
    "\n",
    "K_eros_test_mc = K_eros_test - O_test@K_eros_train - K_eros_test@O_train + O_test@K_eros_train@O_train\n",
    "\n",
    "Y = K_eros_test_mc @ V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the $i$-th MTS item in the test set is represented as features (length = num examples in the training set) in the $i$-th row of $\\mathbf{Y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((770, 51), (1795, 1795))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape, V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01038961038961039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SC = StandardScaler()\n",
    "SC.fit(V)\n",
    "V_scaled = SC.transform(V)\n",
    "Y_scaled = SC.transform(Y)\n",
    "\n",
    "prova_train = y_train.to_numpy().astype('int')\n",
    "prova_test = y_test.to_numpy().astype('int')\n",
    "'''\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(V[:,:51], y_train)\n",
    "\n",
    "predictions = svc.predict(Y[:,:51])\n",
    "\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_eig_vals = eig_vals/np.sum(eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1358448438450274"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(norm_eig_vals[:51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "391ddcc66a8b67209ee4ca14a5da0cf1073041a687facbd61882e6753a3822ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
