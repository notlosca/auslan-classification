{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import k_eros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'sx_x',\n",
    "    'sx_y',\n",
    "    'sx_z',\n",
    "    'sx_roll',\n",
    "    'sx_pitch',\n",
    "    'sx_yaw',\n",
    "    'sx_thumb',\n",
    "    'sx_forefinger',\n",
    "    'sx_middle_finger',\n",
    "    'sx_ring_finger',\n",
    "    'sx_little_finger',\n",
    "    'dx_x',\n",
    "    'dx_y',\n",
    "    'dx_z',\n",
    "    'dx_roll',\n",
    "    'dx_pitch',\n",
    "    'dx_yaw',\n",
    "    'dx_thumb',\n",
    "    'dx_forefinger',\n",
    "    'dx_middle_finger',\n",
    "    'dx_ring_finger',\n",
    "    'dx_little_finger'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"./tctodd/\"\n",
    "path = \"../../Desktop/MML Project/tctodd/\"\n",
    "dirs = os.listdir(path=path)\n",
    "weeks = sorted([i for i in dirs if i != \".DS_Store\"])\n",
    "filenames = sorted(os.listdir(path+weeks[1]))\n",
    "\n",
    "data = []\n",
    "labels = dict()\n",
    "label_cnt = 0\n",
    "\n",
    "for w in weeks:\n",
    "    temp_path = path+w+\"/\"\n",
    "    filenames = sorted(os.listdir(temp_path))\n",
    "    for fn in filenames:\n",
    "        label = fn.split('.')[0][:-2]\n",
    "        \n",
    "        if label not in labels:\n",
    "            labels[label] = label_cnt\n",
    "            label_cnt += 1\n",
    "            \n",
    "        data.append({'label':labels[label], 'time_series':pd.read_csv(temp_path+fn, header=None, sep='\\t',).values})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     27\n",
      "60    27\n",
      "69    27\n",
      "68    27\n",
      "67    27\n",
      "      ..\n",
      "29    27\n",
      "28    27\n",
      "27    27\n",
      "26    27\n",
      "94    27\n",
      "Name: label, Length: 95, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>time_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.064909, 0.034318, -0.043964, 0.626383, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.107059, -0.126109, -0.053742, 0.612516, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.061427, -0.082576, -0.102991, 0.735469, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.128178, 0.02695, -0.050126, 0.455028, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.143672, -0.144416, -0.047447, 0.660979, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        time_series\n",
       "0      0  [[-0.064909, 0.034318, -0.043964, 0.626383, 0....\n",
       "1      0  [[-0.107059, -0.126109, -0.053742, 0.612516, 0...\n",
       "2      0  [[-0.061427, -0.082576, -0.102991, 0.735469, 0...\n",
       "3      1  [[-0.128178, 0.02695, -0.050126, 0.455028, 0.4...\n",
       "4      1  [[-0.143672, -0.144416, -0.047447, 0.660979, 0..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=['label', 'time_series'])\n",
    "print(df['label'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df['time_series']\n",
    "y = df['label']\n",
    "seed = 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.222222222222222, random_state=seed) # to have 21 and 6 examples in, respectively, train and test set\n",
    "X_train, X_test = X_train.reset_index(drop=True),X_test.reset_index(drop=True)\n",
    "y_train, y_test = y_train.reset_index(drop=True), y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    21\n",
       "23    21\n",
       "8     21\n",
       "61    21\n",
       "44    21\n",
       "      ..\n",
       "53    21\n",
       "9     21\n",
       "64    21\n",
       "93    21\n",
       "94    21\n",
       "Name: label, Length: 95, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "n_folds = 5\n",
    "skf = sk.model_selection.StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 0\n",
    "n_pcs = 54\n",
    "\n",
    "##LINEAR KERNEL\n",
    "params = [['linear'], [0.0001, 0.0005, 0.001, 0.005, 0.01, 1]]\n",
    "params_comb = list(itertools.product(*params))\n",
    "\n",
    "##RBF KERNEL\n",
    "params = [['rbf'], [0.0001, 0.0005, 0.001, 0.005, 0.01, 1], [0.001, 0.01, 1, 2, 5, 10]]\n",
    "params_comb += list(itertools.product(*params))\n",
    "\n",
    "##POLYNOMIAL KERNEL\n",
    "params = [['poly'], [1e-5, 0.0001, 0.0005, 0.001, 0.005, 0.01, 1], [0.001, 0.01, 1, 2, 5, 10], [3, 6, 10, 15, 20, 23, 25, 30], [0, 0.1, 0.5, 1, 5, 10]]\n",
    "params_comb += list(itertools.product(*params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "doing parameters search...: 100%|█████████▉| 2053/2058 [14:18<00:02,  2.49it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...: 100%|██████████| 2058/2058 [14:20<00:00,  2.39it/s]\n",
      "doing parameters search...:  30%|██▉       | 614/2058 [04:08<09:23,  2.56it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...: 100%|█████████▉| 2054/2058 [13:44<00:01,  2.38it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...: 100%|██████████| 2058/2058 [13:46<00:00,  2.49it/s]\n",
      "doing parameters search...:  99%|█████████▉| 2047/2058 [13:01<00:04,  2.51it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...: 100%|█████████▉| 2054/2058 [13:04<00:01,  2.53it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...: 100%|██████████| 2058/2058 [13:05<00:00,  2.62it/s]\n",
      "doing parameters search...:  44%|████▍     | 902/2058 [05:47<07:22,  2.61it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...:  58%|█████▊    | 1190/2058 [07:42<06:31,  2.22it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...:  72%|███████▏  | 1478/2058 [09:34<03:43,  2.59it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...:  86%|████████▌ | 1766/2058 [11:23<01:53,  2.56it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...: 100%|█████████▉| 2054/2058 [13:09<00:01,  2.60it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...: 100%|██████████| 2058/2058 [13:10<00:00,  2.60it/s]\n",
      "doing parameters search...:  16%|█▌        | 326/2058 [02:07<10:59,  2.63it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...:  44%|████▍     | 902/2058 [05:41<07:22,  2.61it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...:  72%|███████▏  | 1478/2058 [09:15<04:02,  2.39it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...:  99%|█████████▉| 2041/2058 [12:39<00:06,  2.74it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...: 100%|█████████▉| 2054/2058 [12:44<00:01,  2.63it/s]c:\\Users\\andre\\VsCodeProjects\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "doing parameters search...: 100%|██████████| 2058/2058 [12:45<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best combination! ('poly', 0.005, 5, 30, 1) w. accuracy of 0.9488721804511278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc_scores = np.zeros(len(params_comb))\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_cv = X_train.iloc[train_index]\n",
    "    y_train_cv = y_train.iloc[train_index]\n",
    "    X_val_cv = X_train.iloc[val_index]\n",
    "    y_val_cv = y_train.iloc[val_index]\n",
    "    X_train_matrix = np.vstack(X_train_cv)\n",
    "    means_train = np.mean(X_train_matrix, axis=0)\n",
    "    stds_train = np.std(X_train_matrix, axis=0)\n",
    "\n",
    "    S, v_list_train = k_eros.compute_S_matrix(X_train_cv, means_train, stds_train)\n",
    "    _, v_list_test = k_eros.compute_S_matrix(X_val_cv, means_train, stds_train)\n",
    "    w = k_eros.compute_weight_vector(S, algorithm=2)\n",
    "    K_eros_train_mc, V, _ = k_eros.perform_PCA(len(X_train_cv), weight_vector=w, v_list=v_list_train)\n",
    "    Y, _ = k_eros.project_test_data(len(X_train_cv), len(X_val_cv), w, v_list_train, v_list_test, K_eros_train_mc, V)\n",
    "    princ_components = V[:, :n_pcs]\n",
    "    test_princ_components = Y[:, :n_pcs]\n",
    "    for i, params in enumerate(tqdm(params_comb, desc='doing parameters search...')):\n",
    "        if len(params) == 2:\n",
    "            combination = tuple([params[0], params[1], 1, 3, 0])\n",
    "        elif len(params) == 3:\n",
    "            combination = tuple([params[0], params[1], params[2], 3, 0])\n",
    "        else:\n",
    "            combination = params\n",
    "        svc = SVC(kernel=combination[0], C=combination[1], gamma=combination[2], degree=combination[3], coef0=combination[4], max_iter=10000)\n",
    "        \n",
    "        svc.fit(princ_components, y_train_cv.values)\n",
    "        \n",
    "        predictions = svc.predict(test_princ_components)\n",
    "        res = accuracy_score(y_val_cv.values, predictions)\n",
    "        acc_scores[i] += res\n",
    "acc_scores = acc_scores / n_folds\n",
    "best_idx = np.argmax(acc_scores)    \n",
    "print(f'Found best combination! {params_comb[best_idx]} w. accuracy of {acc_scores[best_idx]}.')\n",
    "best_comb = params_comb[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached an accuracy of 0.9578947368421052.\n",
      "svc_res_per_pc: [0.02105263 0.33333333 0.6877193  0.86140351 0.88947368 0.93508772\n",
      " 0.94035088 0.94736842 0.96315789 0.95438596 0.95789474 0.95789474]\n"
     ]
    }
   ],
   "source": [
    "n_princ_cs = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 54]\n",
    "res_per_pc = np.zeros(len(n_princ_cs))\n",
    "\n",
    "X_train_matrix = np.vstack(X_train)\n",
    "means_train = np.mean(X_train_matrix, axis=0)\n",
    "stds_train = np.std(X_train_matrix, axis=0)\n",
    "\n",
    "S, v_list_train = k_eros.compute_S_matrix(X_train, means_train, stds_train)\n",
    "_, v_list_test = k_eros.compute_S_matrix(X_test, means_train, stds_train)\n",
    "w = k_eros.compute_weight_vector(S, algorithm=2)\n",
    "K_eros_train_mc, V, eig_vals = k_eros.perform_PCA(len(X_train), weight_vector=w, v_list=v_list_train)\n",
    "Y, K_eros_test_mc = k_eros.project_test_data(len(X_train), len(X_test), w, v_list_train, v_list_test, K_eros_train_mc, V)\n",
    "svc = SVC(kernel=best_comb[0], C=best_comb[1], gamma=best_comb[2], degree=best_comb[3], coef0=best_comb[4])\n",
    "for i, n_pc in enumerate(n_princ_cs):\n",
    "    princ_components = V[:, :n_pc]\n",
    "    svc.fit(princ_components, y_train.values)\n",
    "    test_princ_components = Y[:, :n_pc]\n",
    "    predictions = svc.predict(test_princ_components)\n",
    "    res = accuracy_score(y_test.values, predictions)\n",
    "    res_per_pc[i] = res\n",
    "print(f'Reached an accuracy of {res_per_pc[-1]}.')\n",
    "svc_res_per_pc = res_per_pc\n",
    "print(f\"svc_res_per_pc: {svc_res_per_pc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [33:01<00:00,  4.40s/it]\n",
      "100%|██████████| 450/450 [31:34<00:00,  4.21s/it]\n",
      "100%|██████████| 450/450 [31:00<00:00,  4.13s/it]\n",
      "100%|██████████| 450/450 [31:22<00:00,  4.18s/it]\n",
      "100%|██████████| 450/450 [31:20<00:00,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best combination! {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200} w. accuracy of 0.5157894736842106.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import itertools\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from tqdm import tqdm\n",
    "criterion = ['gini', 'entropy']\n",
    "n_estimators = [10, 25, 50, 100, 200]\n",
    "max_depth = [10, 20, 30, 50, 100]\n",
    "min_samples_split = [2, 6, 10] # minimum sample number to split a node\n",
    "min_samples_leaf = [1, 3, 4] # minimum sample number that can be stored in a leaf node\n",
    "params_grid = {\n",
    "    'criterion': criterion,\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "}\n",
    "n_pcs = 54\n",
    "n_coords = 60\n",
    "params_list = list(ParameterGrid(params_grid))\n",
    "acc_scores = np.zeros(len(params_list))\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_cv = X_train.iloc[train_index]\n",
    "    y_train_cv = y_train.iloc[train_index]\n",
    "    X_val_cv = X_train.iloc[val_index]\n",
    "    y_val_cv = y_train.iloc[val_index]\n",
    "    X_train_matrix = np.vstack(X_train_cv)\n",
    "    means_train = np.mean(X_train_matrix, axis=0)\n",
    "    stds_train = np.std(X_train_matrix, axis=0)\n",
    "    S, v_list_train = k_eros.compute_S_matrix(X_train_cv, means_train, stds_train)\n",
    "    _, v_list_test = k_eros.compute_S_matrix(X_val_cv, means_train, stds_train)\n",
    "    w = k_eros.compute_weight_vector(S, algorithm=2)\n",
    "    K_eros_train_mc, V, eig_vals = k_eros.perform_PCA(len(X_train_cv), weight_vector=w, v_list=v_list_train)\n",
    "    Y, K_eros_test_mc = k_eros.project_test_data(len(X_train_cv), len(X_val_cv), w, v_list_train, v_list_test, K_eros_train_mc, V)\n",
    "    princ_components = V[:, :n_pcs]\n",
    "    test_princ_components = Y[:, :n_pcs]\n",
    "    for i, params in enumerate(tqdm(params_list)):\n",
    "        rf = RandomForestClassifier(criterion = params['criterion'], n_estimators=params['n_estimators'], max_depth=params['max_depth'], min_samples_split=params['min_samples_split'], min_samples_leaf=params['min_samples_leaf'])\n",
    "        rf.fit(princ_components, y_train_cv.values)\n",
    "        predictions = rf.predict(test_princ_components)\n",
    "        res = accuracy_score(y_val_cv.values, predictions)\n",
    "        acc_scores[i] += res\n",
    "acc_scores = acc_scores / n_folds\n",
    "best_idx = np.argmax(acc_scores)    \n",
    "print(f'Found best combination! {params_list[best_idx]} w. accuracy of {acc_scores[best_idx]}.')\n",
    "best_comb = params_list[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best combination! {'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200} w. accuracy of 0.5157894736842106.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 30,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Found best combination! {params_list[best_idx]} w. accuracy of {acc_scores[best_idx]}.')\n",
    "best_comb = params_list[best_idx]\n",
    "params_list[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached an accuracy of 0.49122807017543857.\n",
      "rf_res_per_pc: [0.02105263 0.14736842 0.26140351 0.41578947 0.4122807  0.51052632\n",
      " 0.48421053 0.48421053 0.51052632 0.50877193 0.47192982 0.49122807]\n"
     ]
    }
   ],
   "source": [
    "#for the best params combination il valore dell accuracy per 10Kfold\n",
    "n_princ_cs = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55]\n",
    "res_per_pc = np.zeros(len(n_princ_cs))\n",
    "X_train_matrix = np.vstack(X_train)\n",
    "means_train = np.mean(X_train_matrix, axis=0)\n",
    "stds_train = np.std(X_train_matrix, axis=0)\n",
    "\n",
    "S, v_list_train = k_eros.compute_S_matrix(X_train, means_train, stds_train)\n",
    "_, v_list_test = k_eros.compute_S_matrix(X_test, means_train, stds_train)\n",
    "w = k_eros.compute_weight_vector(S, algorithm=2)\n",
    "K_eros_train_mc, V, eig_vals = k_eros.perform_PCA(len(X_train), weight_vector=w, v_list=v_list_train)\n",
    "Y, K_eros_test_mc = k_eros.project_test_data(len(X_train), len(X_test), w, v_list_train, v_list_test, K_eros_train_mc, V)\n",
    "rf = RandomForestClassifier(**best_comb)\n",
    "for i, n_pc in enumerate(n_princ_cs):\n",
    "    princ_components = V[:, :n_pc]\n",
    "    rf.fit(princ_components, y_train.values)\n",
    "    test_princ_components = Y[:, :n_pc]\n",
    "    predictions = rf.predict(test_princ_components)\n",
    "    res = accuracy_score(y_test.values, predictions)\n",
    "    res_per_pc[i] += res\n",
    "\n",
    "print(f'Reached an accuracy of {res_per_pc[-1]}.')\n",
    "rf_res_per_pc = res_per_pc\n",
    "print(f'rf_res_per_pc: {rf_res_per_pc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC accuracy x n principal components:  [0.02105263 0.33333333 0.6877193  0.86140351 0.88947368 0.93508772\n",
      " 0.94035088 0.94736842 0.96315789 0.95438596 0.95789474 0.95789474]\n",
      "RF accuracy x n principal components:  [0.02105263 0.14736842 0.26140351 0.41578947 0.4122807  0.51052632\n",
      " 0.48421053 0.48421053 0.51052632 0.50877193 0.47192982 0.49122807]\n"
     ]
    }
   ],
   "source": [
    "print('SVC accuracy x n principal components: ', svc_res_per_pc)\n",
    "print('RF accuracy x n principal components: ', rf_res_per_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "822e9953ea62b7387f865effc68cd2c9a820139fdd7cc55e9bddd4bde161cc3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
