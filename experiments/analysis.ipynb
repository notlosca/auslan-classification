{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = [\n",
    "    'sx_roll',\n",
    "    'sx_pitch',\n",
    "    'sx_yaw',\n",
    "    'sx_thumb',\n",
    "    'sx_x',\n",
    "    'sx_y',\n",
    "    'sx_z',\n",
    "    'sx_forefinger',\n",
    "    'sx_middle_finger',\n",
    "    'sx_ring_finger',\n",
    "    'sx_little_finger',\n",
    "    'dx_roll',\n",
    "    'dx_pitch',\n",
    "    'dx_yaw',\n",
    "    'dx_x',\n",
    "    'dx_y',\n",
    "    'dx_z',\n",
    "    'dx_thumb',\n",
    "    'dx_forefinger',\n",
    "    'dx_middle_finger',\n",
    "    'dx_ring_finger',\n",
    "    'dx_little_finger'\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../Desktop/MML Project/tctodd/\"\n",
    "dirs = os.listdir(path=path)\n",
    "weeks = sorted([i for i in dirs if i != \".DS_Store\"])\n",
    "filenames = sorted(os.listdir(path+weeks[1]))\n",
    "\n",
    "data = []\n",
    "labels = dict()\n",
    "label_cnt = 0\n",
    "\n",
    "for w in weeks:\n",
    "    temp_path = path+w+\"/\"\n",
    "    filenames = sorted(os.listdir(temp_path))\n",
    "    for fn in filenames:\n",
    "        label = fn.split('.')[0][:-2]\n",
    "        \n",
    "        if label not in labels:\n",
    "            labels[label] = label_cnt\n",
    "            label_cnt += 1\n",
    "            \n",
    "        data.append({'label':labels[label], 'time_series':pd.read_csv(temp_path+fn, header=None, sep='\\t',).values})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had to change her label in tctodd1 in his_hers. Otherwise 96 labels instead of 95.\n",
    "vedere se le varie label di his_hers sono statisticamente simili (che vuol dire statisticamente? boh guardiamo media e dev. std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     27\n",
      "60    27\n",
      "69    27\n",
      "68    27\n",
      "67    27\n",
      "      ..\n",
      "29    27\n",
      "28    27\n",
      "27    27\n",
      "26    27\n",
      "94    27\n",
      "Name: label, Length: 95, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>time_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.064909, 0.034318, -0.043964, 0.626383, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.107059, -0.126109, -0.053742, 0.612516, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.061427, -0.082576, -0.102991, 0.735469, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.128178, 0.02695, -0.050126, 0.455028, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.143672, -0.144416, -0.047447, 0.660979, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        time_series\n",
       "0      0  [[-0.064909, 0.034318, -0.043964, 0.626383, 0....\n",
       "1      0  [[-0.107059, -0.126109, -0.053742, 0.612516, 0...\n",
       "2      0  [[-0.061427, -0.082576, -0.102991, 0.735469, 0...\n",
       "3      1  [[-0.128178, 0.02695, -0.050126, 0.455028, 0.4...\n",
       "4      1  [[-0.143672, -0.144416, -0.047447, 0.660979, 0..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=['label', 'time_series'])\n",
    "print(df['label'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12359908,  0.02004841, -0.04530714,  0.47213429,  0.53506589,\n",
       "        0.49491324,  0.17544914,  0.19811941,  0.17947179,  0.20405468,\n",
       "        0.21601179,  0.07842527,  0.06782231, -0.03748164,  0.38855008,\n",
       "        0.5130405 ,  0.55184169,  0.19595423,  0.05150761,  0.18715093,\n",
       "        0.1726928 ,  0.33196956])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df['time_series'].iloc[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.29005847953216\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for i in range(len(df)):\n",
    "    lengths.append(df.iloc[i]['time_series'].shape[0])\n",
    "print(np.mean(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.064909,  0.034318, -0.043964, ...,  1.      ,  0.754117,\n",
       "         1.      ],\n",
       "       [-0.033878,  0.034764, -0.032445, ...,  1.      ,  0.97451 ,\n",
       "         1.      ],\n",
       "       [ 0.015014,  0.030924, -0.012665, ...,  1.      ,  1.      ,\n",
       "         1.      ],\n",
       "       ...,\n",
       "       [-0.158942,  0.009224, -0.057761, ...,  0.      ,  0.      ,\n",
       "         0.172542],\n",
       "       [-0.162514,  0.00717 , -0.05785 , ...,  0.      ,  0.      ,\n",
       "         0.172542],\n",
       "       [-0.163496,  0.006947, -0.058029, ...,  0.      ,  0.      ,\n",
       "         0.172542]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['time_series'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 0\n",
    "\n",
    "# Shuffle the dataframe\n",
    "shuffled_df = sk.utils.shuffle(df, random_state=seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(shuffled_df['time_series'], shuffled_df['label'], stratify=shuffled_df['label'],  train_size=.9, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 24]\n",
      " [ 1 24]\n",
      " [ 2 25]\n",
      " [ 3 24]\n",
      " [ 4 24]\n",
      " [ 5 24]\n",
      " [ 6 25]\n",
      " [ 7 25]\n",
      " [ 8 25]\n",
      " [ 9 24]\n",
      " [10 24]\n",
      " [11 24]\n",
      " [12 24]\n",
      " [13 25]\n",
      " [14 24]\n",
      " [15 24]\n",
      " [16 25]\n",
      " [17 24]\n",
      " [18 24]\n",
      " [19 24]\n",
      " [20 24]\n",
      " [21 24]\n",
      " [22 25]\n",
      " [23 24]\n",
      " [24 25]\n",
      " [25 24]\n",
      " [26 25]\n",
      " [27 24]\n",
      " [28 24]\n",
      " [29 24]\n",
      " [30 25]\n",
      " [31 24]\n",
      " [32 24]\n",
      " [33 25]\n",
      " [34 24]\n",
      " [35 24]\n",
      " [36 24]\n",
      " [37 24]\n",
      " [38 24]\n",
      " [39 24]\n",
      " [40 24]\n",
      " [41 24]\n",
      " [42 25]\n",
      " [43 25]\n",
      " [44 24]\n",
      " [45 25]\n",
      " [46 24]\n",
      " [47 24]\n",
      " [48 25]\n",
      " [49 24]\n",
      " [50 24]\n",
      " [51 25]\n",
      " [52 24]\n",
      " [53 24]\n",
      " [54 24]\n",
      " [55 24]\n",
      " [56 25]\n",
      " [57 24]\n",
      " [58 24]\n",
      " [59 24]\n",
      " [60 25]\n",
      " [61 25]\n",
      " [62 25]\n",
      " [63 24]\n",
      " [64 24]\n",
      " [65 24]\n",
      " [66 24]\n",
      " [67 24]\n",
      " [68 24]\n",
      " [69 24]\n",
      " [70 24]\n",
      " [71 24]\n",
      " [72 24]\n",
      " [73 25]\n",
      " [74 25]\n",
      " [75 24]\n",
      " [76 25]\n",
      " [77 24]\n",
      " [78 24]\n",
      " [79 25]\n",
      " [80 25]\n",
      " [81 24]\n",
      " [82 24]\n",
      " [83 24]\n",
      " [84 24]\n",
      " [85 24]\n",
      " [86 24]\n",
      " [87 24]\n",
      " [88 25]\n",
      " [89 24]\n",
      " [90 25]\n",
      " [91 24]\n",
      " [92 24]\n",
      " [93 24]\n",
      " [94 25]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train.values, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  3]\n",
      " [ 1  3]\n",
      " [ 2  2]\n",
      " [ 3  3]\n",
      " [ 4  3]\n",
      " [ 5  3]\n",
      " [ 6  2]\n",
      " [ 7  2]\n",
      " [ 8  2]\n",
      " [ 9  3]\n",
      " [10  3]\n",
      " [11  3]\n",
      " [12  3]\n",
      " [13  2]\n",
      " [14  3]\n",
      " [15  3]\n",
      " [16  2]\n",
      " [17  3]\n",
      " [18  3]\n",
      " [19  3]\n",
      " [20  3]\n",
      " [21  3]\n",
      " [22  2]\n",
      " [23  3]\n",
      " [24  2]\n",
      " [25  3]\n",
      " [26  2]\n",
      " [27  3]\n",
      " [28  3]\n",
      " [29  3]\n",
      " [30  2]\n",
      " [31  3]\n",
      " [32  3]\n",
      " [33  2]\n",
      " [34  3]\n",
      " [35  3]\n",
      " [36  3]\n",
      " [37  3]\n",
      " [38  3]\n",
      " [39  3]\n",
      " [40  3]\n",
      " [41  3]\n",
      " [42  2]\n",
      " [43  2]\n",
      " [44  3]\n",
      " [45  2]\n",
      " [46  3]\n",
      " [47  3]\n",
      " [48  2]\n",
      " [49  3]\n",
      " [50  3]\n",
      " [51  2]\n",
      " [52  3]\n",
      " [53  3]\n",
      " [54  3]\n",
      " [55  3]\n",
      " [56  2]\n",
      " [57  3]\n",
      " [58  3]\n",
      " [59  3]\n",
      " [60  2]\n",
      " [61  2]\n",
      " [62  2]\n",
      " [63  3]\n",
      " [64  3]\n",
      " [65  3]\n",
      " [66  3]\n",
      " [67  3]\n",
      " [68  3]\n",
      " [69  3]\n",
      " [70  3]\n",
      " [71  3]\n",
      " [72  3]\n",
      " [73  2]\n",
      " [74  2]\n",
      " [75  3]\n",
      " [76  2]\n",
      " [77  3]\n",
      " [78  3]\n",
      " [79  2]\n",
      " [80  2]\n",
      " [81  3]\n",
      " [82  3]\n",
      " [83  3]\n",
      " [84  3]\n",
      " [85  3]\n",
      " [86  3]\n",
      " [87  3]\n",
      " [88  2]\n",
      " [89  3]\n",
      " [90  2]\n",
      " [91  3]\n",
      " [92  3]\n",
      " [93  3]\n",
      " [94  2]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_test.values, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each row of the Series object is an array. Classifiers won't read it. We create a matrix of values.\n",
    "def from_series_to_matrix(num_predictors:int, time_series:pd.Series) -> np.ndarray:\n",
    "    \"\"\"Function used to transform the pandas Series to a matrix.\n",
    "    Used to feed classifiers.\n",
    "\n",
    "    Args:\n",
    "        num_predictors (int): numbers of predictors\n",
    "        time_series (pd.Series): time series data\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: NxM matrix where:\n",
    "        - N is the number of examples\n",
    "        - M is the number of predictors\n",
    "    \"\"\"\n",
    "    a = np.zeros(shape=(len(time_series), num_predictors))\n",
    "    for i in range(len(time_series)):\n",
    "        for j in range(num_predictors):\n",
    "            a[i,j] = time_series.iloc[i][j]\n",
    "    return a\n",
    "\n",
    "# compute_mean_feature_vector used to compute baseline\n",
    "def compute_mean_feature_vector(time_series:pd.Series) -> np.ndarray:\n",
    "    \"\"\"Compute the mean of each field of each time series example\n",
    "\n",
    "    Args:\n",
    "        time_series (pd.Series): time series\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: feature vector for each entry\n",
    "    \"\"\"\n",
    "    num_predictors = time_series.iloc[0].shape[-1]\n",
    "    return from_series_to_matrix(num_predictors, time_series.apply(lambda x: np.mean(x, axis=0)))\n",
    "\n",
    "X_train_mean_fv = compute_mean_feature_vector(X_train)\n",
    "X_test_mean_fv = compute_mean_feature_vector(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SC = StandardScaler()\n",
    "SC.fit(X_train_mean_fv)\n",
    "matrix_X_train_mean_fv_scaled = SC.transform(X_train_mean_fv)\n",
    "matrix_X_test_mean_fv_scaled = SC.transform(X_test_mean_fv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:   0%|          | 1/2268 [00:00<20:44,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.14785992217898833, best combination: kernel:linear, C=1e-05, gamma=1e-05, degree=2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:   8%|▊         | 190/2268 [01:53<17:38,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.5953307392996109, best combination: kernel:linear, C=0.01, gamma=1e-05, degree=2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  11%|█         | 253/2268 [02:19<12:59,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.8326848249027238, best combination: kernel:linear, C=0.1, gamma=1e-05, degree=2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  14%|█▍        | 316/2268 [02:41<11:18,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.8560311284046692, best combination: kernel:linear, C=1, gamma=1e-05, degree=2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..: 100%|██████████| 2268/2268 [23:36<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy score: 0.8560311284046692, best combination: kernel:linear, C=1, gamma=1e-05, degree=2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm\n",
    "best_acc_score = 0\n",
    "best_combination = ''\n",
    "params = [['linear', 'poly', 'rbf', 'sigmoid'], [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10], [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10],[2, 3, 5, 6, 8, 9, 10]]\n",
    "params_comb = list(itertools.product(*params))\n",
    "\n",
    "for params in tqdm(params_comb, desc='calculating diff params combinations..'):\n",
    "    svc = SVC(kernel=params[0], C=params[1], gamma = params[2], degree= params[3])\n",
    "    svc.fit(matrix_X_train_mean_fv_scaled, y_train.values)\n",
    "    predictions = svc.predict(matrix_X_test_mean_fv_scaled)\n",
    "    res = accuracy_score(y_test.values, predictions)\n",
    "    if res > best_acc_score:\n",
    "        best_acc_score = res\n",
    "        best_combination = f'kernel:{params[0]}, C={params[1]}, gamma={params[2]}, degree={params[3]}.'\n",
    "        print(f'found new best acc score! {best_acc_score}, best combination: {best_combination}')\n",
    "print(f'best accuracy score: {best_acc_score}, best combination: {best_combination}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_S_matrix(ts_series:pd.Series, means:np.array, vars:np.array) -> tuple:\n",
    "    \"\"\"function to compute the S matrix of shape n x N (n = number of predictors, N = number of examples). \n",
    "    Such matrix will be used to compute\n",
    "    the weight vector needed by Eros norm\n",
    "\n",
    "    Args:\n",
    "        -ts_series (pd.Series): Series containing the dataset of time series.\n",
    "        Each entry is a list of vectors. \n",
    "        Each vector is a component of the i-th time series\n",
    "        -means (np.array): array containing the means of the features in order to scale them\n",
    "        -vars (np.array): array containing the vars of the features in order to scale them\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.array, list]: returns the matrix S and the list of\n",
    "        right eigenvectors matrices computed for each time series\n",
    "    \"\"\"\n",
    "    s_matrix = np.zeros(shape=(len(ts_series), ts_series.iloc[0].shape[-1]))\n",
    "    v_list = [] # list of right eigenvector matrix\n",
    "    for i in range(len(ts_series)):\n",
    "        ts = ts_series.iloc[i] # time x predictors\n",
    "        #The matrix S will be nxN where n is the predictor dimension and N is the number of time-series examples.\n",
    "        #Hence, we will use the transpose to compute the covariance matrix.\n",
    "        ts = (ts - means)/vars\n",
    "        ts = ts.T # predictors x time\n",
    "        #Compute the covariance matrix of the i-th example of the dataset\n",
    "        #cov_ts = np.corrcoef(ts)\n",
    "        cov_ts = np.cov(ts)\n",
    "        # Compute the SVD of the covariance matrix\n",
    "        u, s, v_t = np.linalg.svd(cov_ts)\n",
    "        s_matrix[i] = s\n",
    "        v_list.append(v_t.T)\n",
    "    return s_matrix.T, v_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matrix = np.vstack(X_train)\n",
    "means_train = np.mean(X_train_matrix, axis=0)\n",
    "vars_train = np.var(X_train_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.05552374, -0.11289002, -0.13787006,  0.59797003,  0.30809794,\n",
       "         0.46319201,  0.08904312,  0.05249049,  0.03018527,  0.05478745,\n",
       "         0.0710108 ,  0.05099855, -0.04383498, -0.1204966 ,  0.43707669,\n",
       "         0.39037003,  0.54879382,  0.28033495,  0.05691277,  0.22594754,\n",
       "         0.13801296,  0.26404592]),\n",
       " array([0.00188294, 0.00639601, 0.00431505, 0.00793959, 0.01775536,\n",
       "        0.00275456, 0.05224821, 0.02878818, 0.02108311, 0.03239591,\n",
       "        0.03702743, 0.00397724, 0.01943236, 0.00798253, 0.00815517,\n",
       "        0.02802097, 0.00769526, 0.13196413, 0.04176523, 0.12569881,\n",
       "        0.0930127 , 0.12833541]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_train, vars_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, v_list_train = compute_S_matrix(X_train, means_train, vars_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, v_list_test = compute_S_matrix(X_test, means_train, vars_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight_vector(S:np.ndarray, aggregation:str='mean', algorithm:int=1) -> np.array:\n",
    "    \"\"\"compute the weight vector used in the computation of Eros norm\n",
    "\n",
    "    Args:\n",
    "        S (np.ndarray): matrix containing eigenvalues of each predictor\n",
    "        aggregation (str, optional): aggregation function to use. Defaults to 'mean'.\n",
    "        algorithm(int): choose the algorithm to use to compute weight vector.\n",
    "        - Algorithm 1: do not normalize rows of the S matrix. Perform directly the computation of w\n",
    "        - Algorithm 2: first normalize rows of the S matrix and then compute w.\n",
    "    Returns:\n",
    "        np.array: return the normalized weight vector\n",
    "    \"\"\"\n",
    "    n = S.shape[0] # number of predictors\n",
    "    if (algorithm == 2):\n",
    "        # first normalize each eigenvalues\n",
    "        S = S/np.sum(S, axis=0)\n",
    "    if (aggregation == 'mean'):\n",
    "        w = np.mean(S, axis=-1)\n",
    "    elif (aggregation == 'min'):\n",
    "        w = np.min(S, axis=-1)\n",
    "    elif (aggregation == 'max'):\n",
    "        w = np.max(S, axis=-1)\n",
    "    return w/np.sum(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = compute_weight_vector(S, algorithm=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eros_norm(weight_vector:np.array, A:np.array, B:np.array):\n",
    "    \"\"\"compute eros norm\n",
    "\n",
    "    Args:\n",
    "        weight_vector (np.array): weight vector\n",
    "        A (np.array): time_series_1\n",
    "        B (np.array): time_series_2\n",
    "\n",
    "    Returns:\n",
    "        float: distance between the 2 time series. Bounded in (0,1]\n",
    "    \"\"\"\n",
    "    # since we want to use a_i and b_i which \n",
    "    # are the orthonormal column vectors of A and B,\n",
    "    # we decide to transpose A and B\n",
    "    A = A.T\n",
    "    B = B.T\n",
    "    n = A.shape[0] # number of predictors\n",
    "\n",
    "    \n",
    "    eros = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        eros += weight_vector[i]*np.abs(np.dot(A[i], B[i]))\n",
    "    return eros\n",
    "\n",
    "def compute_kernel_matrix(num_examples:int, weight_vector:np.array, v_list:list) -> np.array:\n",
    "    \"\"\"compute the kernel matrix to be used in PCA\n",
    "\n",
    "    Args:\n",
    "        num_examples (int): number of examples in the dataset\n",
    "        weight_vector (np.array): weight vector \n",
    "        v_t_list (list[np.array]): list of right eigenvector matrices\n",
    "\n",
    "    Returns:\n",
    "        np.array: kernel matrix with pairwise eros norm\n",
    "    \"\"\"\n",
    "    N = num_examples\n",
    "    K_eros = np.zeros(shape=(N,N))\n",
    "\n",
    "    for i in range(N):\n",
    "        j = 0\n",
    "        while (j <= i):\n",
    "            K_eros[i,j] = eros_norm(weight_vector, v_list[i], v_list[j])\n",
    "            if (i != j): \n",
    "                K_eros[j,i] = K_eros[i,j]\n",
    "            j += 1\n",
    "\n",
    "    # check whether the kernel matrix is positive semi definite (PSD) or not\n",
    "    is_psd = np.all(np.linalg.eigvals(K_eros) >= 0)\n",
    "    #is_psd = True\n",
    "    print(np.min(np.linalg.eigvals(K_eros)))\n",
    "    threshold = 1e-10\n",
    "    # if not PSD, add to the diagonal the minimal value among eigenvalues of K_eros\n",
    "    if is_psd == False:\n",
    "        delta = np.min(np.linalg.eigvals(K_eros))\n",
    "        delta_ary = [np.abs(delta) + threshold for _ in range(K_eros.shape[0])]\n",
    "        K_eros += np.diag(delta_ary)\n",
    "    is_psd = np.all(np.linalg.eigvals(K_eros) >= 0)\n",
    "    if is_psd == True:\n",
    "        print(\"now PSD\")\n",
    "    else:\n",
    "        print(\"not PSD\")\n",
    "    return K_eros\n",
    "\n",
    "def perform_PCA(num_examples:int, weight_vector:np.array, v_list:list) -> tuple:\n",
    "    \"\"\"extract principal components in the feature space\n",
    "\n",
    "    Args:\n",
    "        num_examples (int): number of examples in the dataset\n",
    "        weight_vector (np.array): weight vector \n",
    "        v_t_list (list[np.array]): list of right eigenvector matrices\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.array]:\n",
    "        - K_eros matrix\n",
    "        - eigenvectors (principal components) of the feature space\n",
    "    \"\"\"\n",
    "    K_eros = compute_kernel_matrix(num_examples, weight_vector, v_list)\n",
    "    O = np.ones(shape=(num_examples,num_examples))\n",
    "    O *= 1/num_examples\n",
    "    K_eros_mc = K_eros - O@K_eros - K_eros@O + O@K_eros@O # K_eros mean centered\n",
    "    is_psd = np.all(np.linalg.eigvals(K_eros_mc) >= 0)\n",
    "    print(f\"K eros mean centered is {'not ' if not is_psd else ''}PSD\")\n",
    "    eig_vals, eig_vecs = np.linalg.eig(K_eros_mc)\n",
    "    return K_eros, eig_vecs, eig_vals\n",
    "\n",
    "\n",
    "def project_test_data(num_training_examples:int, num_test_examples:int, weight_vector:np.array, v_list_train:list, v_list_test:list, K_eros_train:np.ndarray, V:np.ndarray) -> tuple:\n",
    "    \"\"\"compute the K eros test kernel matrix used to project test data\n",
    "\n",
    "    Args:\n",
    "        num_examples_train (int): number of examples in the training dataset\n",
    "        num_examples_test (int): number of examples in the test dataset\n",
    "        weight_vector (np.array): weight vector \n",
    "        v_list_train (list[np.array]): list of right eigenvector matrices of the training dataset\n",
    "        v_list_test (list[np.array]): list of right eigenvector matrices of the test dataset\n",
    "\n",
    "    Returns:\n",
    "        np.array: kernel matrix with pairwise eros norm\n",
    "    \"\"\"\n",
    "    N_train = num_training_examples\n",
    "    N_test = num_test_examples\n",
    "    K_eros_test = np.zeros(shape=(N_test,N_train))\n",
    "\n",
    "    for i in range(N_test):\n",
    "        for j in range(N_train):\n",
    "            K_eros_test[i,j] = eros_norm(weight_vector, v_list_test[i], v_list_train[j])\n",
    "    \n",
    "    O_test = np.ones(shape=(N_test, N_train))*(1/N_train)\n",
    "    O_train = np.ones(shape=(N_train, N_train))*(1/N_train)\n",
    "\n",
    "    K_eros_test_mc = K_eros_test - O_test@K_eros_train - K_eros_test@O_train + O_test@K_eros_train@O_train\n",
    "\n",
    "    Y = K_eros_test_mc @ V\n",
    "    \n",
    "    return Y, K_eros_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-27.709595645972787\n",
      "now PSD\n",
      "K eros mean centered is PSD\n"
     ]
    }
   ],
   "source": [
    "K_eros_train, V, eig_vals = perform_PCA(len(X_train), weight_vector=w, v_list=v_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, K_eros_test = project_test_data(len(X_train), len(X_test), w, v_list_train, v_list_test, K_eros_train, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "kpca = KernelPCA(n_components=None, kernel='precomputed')\n",
    "principal_comps_train = kpca.fit_transform(K_eros_train)\n",
    "principal_comps_test = kpca.transform(K_eros_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2308, 2308), (257, 2308), (2308, 2307), (257, 2307))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape, Y.shape, principal_comps_train.shape, principal_comps_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:   0%|          | 1/3888 [00:00<45:51,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.19066147859922178, best combination: kernel:linear, C=1e-05, gamma=1e-05, degree=15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  11%|█         | 433/3888 [05:23<38:14,  1.51it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.2140077821011673, best combination: kernel:linear, C=0.1, gamma=1e-05, degree=15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  14%|█▍        | 541/3888 [06:32<38:50,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.6653696498054474, best combination: kernel:linear, C=1, gamma=1e-05, degree=15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  17%|█▋        | 649/3888 [07:46<33:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.7003891050583657, best combination: kernel:linear, C=2, gamma=1e-05, degree=15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  27%|██▋       | 1057/3888 [11:56<35:36,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.7859922178988327, best combination: kernel:poly, C=1e-05, gamma=5, degree=15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  27%|██▋       | 1058/3888 [11:57<34:45,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.7976653696498055, best combination: kernel:poly, C=1e-05, gamma=5, degree=16.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  27%|██▋       | 1060/3888 [11:58<34:05,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.8093385214007782, best combination: kernel:poly, C=1e-05, gamma=5, degree=20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  27%|██▋       | 1061/3888 [11:59<33:42,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.8132295719844358, best combination: kernel:poly, C=1e-05, gamma=5, degree=22.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  27%|██▋       | 1062/3888 [12:00<34:03,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.8171206225680934, best combination: kernel:poly, C=1e-05, gamma=5, degree=23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  31%|███       | 1188/3888 [13:41<45:53,  1.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.8210116731517509, best combination: kernel:poly, C=0.0001, gamma=10, degree=30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..: 100%|██████████| 3888/3888 [53:07<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy score: 0.8210116731517509, best combination: kernel:poly, C=0.0001, gamma=10, degree=30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###BASIC param search on our version of KPCA with eros\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "best_acc_score = 0\n",
    "best_combination = ''\n",
    "params = [['linear', 'poly', 'rbf', 'sigmoid'], [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10], [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 2, 5, 10],[15,16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 30]]\n",
    "params_comb = list(itertools.product(*params))\n",
    "for params in tqdm(params_comb, desc='calculating diff params combinations..'):\n",
    "    svc = SVC(kernel=params[0], C=params[1], gamma = params[2], degree= params[3])\n",
    "    princ_components = V[:, :51]\n",
    "    svc.fit(princ_components, y_train.values)\n",
    "    test_princ_components = Y[:, :51]\n",
    "    predictions = svc.predict(test_princ_components)\n",
    "    res = accuracy_score(y_test.values, predictions)\n",
    "    if res > best_acc_score:\n",
    "        best_acc_score = res\n",
    "        best_combination = f'kernel:{params[0]}, C={params[1]}, gamma={params[2]}, degree={params[3]}.'\n",
    "        print(f'found new best acc score! {best_acc_score}, best combination: {best_combination}')\n",
    "print(f'best accuracy score: {best_acc_score}, best combination: {best_combination}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:   0%|          | 1/540 [00:01<11:35,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.8132295719844358, best combination: kernel:poly, C=1e-05, gamma=5, degree=25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:   1%|          | 4/540 [00:03<06:53,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.8171206225680934, best combination: kernel:poly, C=1e-05, gamma=5, degree=29.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:   1%|          | 6/540 [00:04<06:35,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.8210116731517509, best combination: kernel:poly, C=1e-05, gamma=5, degree=31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:   9%|▊         | 46/540 [00:32<05:30,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.8249027237354085, best combination: kernel:poly, C=1e-05, gamma=11, degree=31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..: 100%|██████████| 540/540 [06:19<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy score: 0.8249027237354085, best combination: kernel:poly, C=1e-05, gamma=11, degree=31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###DEEPER param search on our version of KPCA with eros (on poly kernel)\n",
    "\n",
    "best_acc_score = 0\n",
    "best_combination = ''\n",
    "params = [['poly'], [0.00001, 0.0005, 0.0001, 0.0005, 0.001, 0.005], [5,8, 9, 10,11,12,13,15,20],[25, 27, 28, 29, 30,31,32,33,35,40]]\n",
    "params_comb = list(itertools.product(*params))\n",
    "for params in tqdm(params_comb, desc='calculating diff params combinations..'):\n",
    "    svc = SVC(kernel=params[0], C=params[1], gamma = params[2], degree= params[3])\n",
    "    princ_components = V[:, :51]\n",
    "    svc.fit(princ_components, y_train.values)\n",
    "    test_princ_components = Y[:, :51]\n",
    "    predictions = svc.predict(test_princ_components)\n",
    "    res = accuracy_score(y_test.values, predictions)\n",
    "    if res > best_acc_score:\n",
    "        best_acc_score = res\n",
    "        best_combination = f'kernel:{params[0]}, C={params[1]}, gamma={params[2]}, degree={params[3]}.'\n",
    "        print(f'found new best acc score! {best_acc_score}, best combination: {best_combination}')\n",
    "print(f'best accuracy score: {best_acc_score}, best combination: {best_combination}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:   0%|          | 1/2160 [00:00<23:45,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.19455252918287938, best combination: kernel:linear, C=1e-05, gamma=5, degree=25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  25%|██▌       | 548/2160 [06:37<25:46,  1.04it/s]"
     ]
    }
   ],
   "source": [
    "#BASIC params search on sklearn KPCA with our kernel (not centered).\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "best_acc_score = 0\n",
    "best_combination = ''\n",
    "params = [['linear', 'poly', 'rbf', 'sigmoid'], [0.00001, 0.0005, 0.0001, 0.0005, 0.001, 0.005], [5,8, 9, 10,11,12,13,15,20],[25, 27, 28, 29, 30,31,32,33,35,40]]\n",
    "params_comb = list(itertools.product(*params))\n",
    "for params in tqdm(params_comb, desc='calculating diff params combinations..'):\n",
    "    svc = SVC(kernel=params[0], C=params[1], gamma = params[2], degree= params[3])\n",
    "    svc.fit(principal_comps_train[:,:51], y_train.values)\n",
    "    predictions = svc.predict(principal_comps_test[:,:51])\n",
    "    res = accuracy_score(y_test.values, predictions)\n",
    "    if res > best_acc_score:\n",
    "        best_acc_score = res\n",
    "        best_combination = f'kernel:{params[0]}, C={params[1]}, gamma={params[2]}, degree={params[3]}.'\n",
    "        print(f'found new best acc score! {best_acc_score}, best combination: {best_combination}')\n",
    "print(f'best accuracy score: {best_acc_score}, best combination: {best_combination}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again KernelPCA but with centered kernel.\n",
    "num_examples_train = K_eros_train.shape[0]\n",
    "num_examples_test = K_eros_test.shape[0]\n",
    "O = np.ones(shape=(num_examples_train,num_examples_train))\n",
    "O *= 1/num_examples_train\n",
    "K_eros_mc_train = K_eros_train - O@K_eros_train - K_eros_train@O + O@K_eros_train@O\n",
    "O_test = np.ones(shape=(num_examples_test, num_examples_train))*(1/num_examples_train)\n",
    "K_eros_mc_test = K_eros_test - O_test@K_eros_train - K_eros_test@O + O_test@K_eros_train@O\n",
    "kpca = KernelPCA(n_components=None, kernel='precomputed')\n",
    "principal_comps_train = kpca.fit_transform(K_eros_mc_train)\n",
    "principal_comps_test = kpca.transform(K_eros_mc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASIC params search on sklearn KPCA with our kernel (centered).\n",
    "\n",
    "best_acc_score = 0\n",
    "best_combination = ''\n",
    "params = [['linear', 'poly', 'rbf', 'sigmoid'], [0.00001, 0.0005, 0.0001, 0.0005, 0.001, 0.005], [5,8, 9, 10,11,12,13,15,20],[25, 27, 28, 29, 30,31,32,33,35,40]]\n",
    "params_comb = list(itertools.product(*params))\n",
    "for params in tqdm(params_comb, desc='calculating diff params combinations..'):\n",
    "    svc = SVC(kernel=params[0], C=params[1], gamma = params[2], degree= params[3])\n",
    "    svc.fit(principal_comps_train[:,:51], y_train.values)\n",
    "    predictions = svc.predict(principal_comps_test[:,:51])\n",
    "    res = accuracy_score(y_test.values, predictions)\n",
    "    if res > best_acc_score:\n",
    "        best_acc_score = res\n",
    "        best_combination = f'kernel:{params[0]}, C={params[1]}, gamma={params[2]}, degree={params[3]}.'\n",
    "        print(f'found new best acc score! {best_acc_score}, best combination: {best_combination}')\n",
    "print(f'best accuracy score: {best_acc_score}, best combination: {best_combination}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolate the dataframe\n",
    "def interpolate_time_series(x:np.ndarray, n_new_coords:int)->np.ndarray:\n",
    "    n_old_coords, n_predictors = x.shape\n",
    "    x_new = np.zeros((n_new_coords, n_predictors))\n",
    "    for i in range(n_predictors):\n",
    "        x_new[:, i] = np.interp(np.linspace(0, n_old_coords, num=n_new_coords), np.array(list(range(n_old_coords))), x[:, i])\n",
    "    return x_new\n",
    "\n",
    "def interpolate_data(X:pd.Series, n_new_coords:int)->pd.Series:\n",
    "    n_examples = len(X)\n",
    "    X_new = X.apply(lambda x : interpolate_time_series(x, n_new_coords))\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_coords = 60\n",
    "X_train_interp, X_test_interp = interpolate_data(X_train, n_coords), interpolate_data(X_test, n_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 22) (56, 22)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_interp.iloc[0].shape, X_train.iloc[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_examples(X:pd.Series)->np.ndarray:\n",
    "    new_x = np.zeros((len(X), (X.iloc[0].shape[1]*n_coords)))\n",
    "    for i in range(len(X)):\n",
    "        new_x[i] = X.iloc[i].flatten()\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_interp.iloc[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_interp = concatenate_examples(X_train_interp)\n",
    "X_test_interp = concatenate_examples(X_test_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1320,), 1320)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_interp[0].shape, 60*22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SC = StandardScaler()\n",
    "SC.fit(X_train_interp)\n",
    "X_train_interp = SC.transform(X_train_interp)\n",
    "X_test_interp = SC.transform(X_test_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform Linear Kernel PCA on the interpolated dataset\n",
    "from sklearn.decomposition import KernelPCA\n",
    "kpca = KernelPCA(n_components=None, kernel='linear')\n",
    "\n",
    "principal_comps_train = kpca.fit_transform(X_train_interp)\n",
    "principal_comps_test = kpca.transform(X_test_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2308, 1225), (257, 1225))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principal_comps_train.shape, principal_comps_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = np.var(principal_comps_train, axis=0)\n",
    "explained_variance_ratio = explained_variance / np.sum(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459232836823346"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(explained_variance_ratio[:51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:   0%|          | 1/2160 [00:00<24:53,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.16342412451361868, best combination: kernel:linear, C=1e-05, gamma=5, degree=25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:   4%|▍         | 91/2160 [00:57<19:53,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.8015564202334631, best combination: kernel:linear, C=0.0005, gamma=5, degree=25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  17%|█▋        | 361/2160 [03:54<17:44,  1.69it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.8988326848249028, best combination: kernel:linear, C=0.001, gamma=5, degree=25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..:  21%|██        | 451/2160 [04:46<15:54,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found new best acc score! 0.9416342412451362, best combination: kernel:linear, C=0.005, gamma=5, degree=25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating diff params combinations..: 100%|██████████| 2160/2160 [28:29<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy score: 0.9416342412451362, best combination: kernel:linear, C=0.005, gamma=5, degree=25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#BASIC params search on Linear KPCA.\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "best_acc_score = 0\n",
    "best_combination = ''\n",
    "params = [['linear', 'poly', 'rbf', 'sigmoid'], [0.00001, 0.0005, 0.0001, 0.0005, 0.001, 0.005], [5,8, 9, 10,11,12,13,15,20],[25, 27, 28, 29, 30,31,32,33,35,40]]\n",
    "params_comb = list(itertools.product(*params))\n",
    "for params in tqdm(params_comb, desc='calculating diff params combinations..'):\n",
    "    svc = SVC(kernel=params[0], C=params[1], gamma = params[2], degree= params[3])\n",
    "    svc.fit(principal_comps_train[:,:51], y_train.values)\n",
    "    predictions = svc.predict(principal_comps_test[:,:51])\n",
    "    res = accuracy_score(y_test.values, predictions)\n",
    "    if res > best_acc_score:\n",
    "        best_acc_score = res\n",
    "        best_combination = f'kernel:{params[0]}, C={params[1]}, gamma={params[2]}, degree={params[3]}.'\n",
    "        print(f'found new best acc score! {best_acc_score}, best combination: {best_combination}')\n",
    "print(f'best accuracy score: {best_acc_score}, best combination: {best_combination}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "391ddcc66a8b67209ee4ca14a5da0cf1073041a687facbd61882e6753a3822ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
