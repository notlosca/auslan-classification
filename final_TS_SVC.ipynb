{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./tctodd/\"\n",
    "#path = \"../../Desktop/MML Project/tctodd/\"\n",
    "dirs = os.listdir(path=path)\n",
    "weeks = sorted([i for i in dirs if i != \".DS_Store\"])\n",
    "filenames = sorted(os.listdir(path+weeks[1]))\n",
    "\n",
    "data = []\n",
    "labels = dict()\n",
    "label_cnt = 0\n",
    "\n",
    "for w in weeks:\n",
    "    temp_path = path+w+\"/\"\n",
    "    filenames = sorted(os.listdir(temp_path))\n",
    "    for fn in filenames:\n",
    "        label = fn.split('.')[0][:-2]\n",
    "        \n",
    "        if label not in labels:\n",
    "            labels[label] = label_cnt\n",
    "            label_cnt += 1\n",
    "            \n",
    "        data.append({'label':labels[label], 'time_series':pd.read_csv(temp_path+fn, header=None, sep='\\t',).values})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "df = pd.DataFrame(data, columns=['label', 'time_series'])\n",
    "seed = 0\n",
    "X = df['time_series']\n",
    "y = df['label']\n",
    "\n",
    "X = to_time_series_dataset(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.222222222222222, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8701754385964913\n"
     ]
    }
   ],
   "source": [
    "from tslearn.svm import TimeSeriesSVC\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "df = pd.DataFrame(data, columns=['label', 'time_series'])\n",
    "seed = 0\n",
    "X = df['time_series']\n",
    "y = df['label']\n",
    "\n",
    "X = to_time_series_dataset(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.222222222222222, random_state=seed)\n",
    "\n",
    "# Scaling\n",
    "\n",
    "# Compute mean and std without taking care of nans\n",
    "X_train_no_nan = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    sample = X_train[i]\n",
    "    mask = ~np.isnan(sample)\n",
    "    sample_no_nan = sample[mask].reshape(-1,22)\n",
    "    X_train_no_nan.append(sample_no_nan)\n",
    "    \n",
    "\n",
    "X_train_no_nan = np.vstack(X_train_no_nan)\n",
    "mean = np.mean(X_train_no_nan, axis=0)\n",
    "std = np.std(X_train_no_nan, axis=0)\n",
    "\n",
    "# Scale everything (train)\n",
    "for i in range(X_train.shape[0]):\n",
    "    sample = X_train[i]\n",
    "    # select entries != nan\n",
    "    mask = ~np.isnan(sample)\n",
    "    sample_no_nan = sample[mask].reshape(-1,22)\n",
    "    scaled = (sample_no_nan - mean) / std\n",
    "    X_train[i].ravel()[:len(scaled.ravel())] = scaled.ravel()\n",
    "\n",
    "# Scale everything (test)\n",
    "for i in range(X_test.shape[0]):\n",
    "    sample = X_test[i]\n",
    "    mask = ~np.isnan(sample)\n",
    "    sample_no_nan = sample[mask].reshape(-1,22)\n",
    "    scaled = (sample_no_nan - mean) / std\n",
    "    X_test[i].ravel()[:len(scaled.ravel())] = scaled.ravel()\n",
    "\n",
    "clf = TimeSeriesSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "res = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.61047705, -0.57930302, -0.07565125, ...,  0.01096043,\n",
       "        -0.4532766 , -0.73419219],\n",
       "       [-0.57661299, -0.60673875, -0.09003222, ...,  0.54181317,\n",
       "        -0.4532766 , -0.65938806],\n",
       "       [-0.57252357, -0.86328223, -0.0879778 , ...,  1.04606729,\n",
       "        -0.4532766 , -0.33016164],\n",
       "       ...,\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''mean_ary = np.zeros(shape=(22,))\n",
    "weights_ary = np.zeros(shape=(22))\n",
    "std_ary = np.zeros(shape=(22,))'''\n",
    "\n",
    "# Compute mean and std without taking care of nans\n",
    "X_train_no_nan = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    sample = X_train[i]\n",
    "    mask = ~np.isnan(sample)\n",
    "    sample_no_nan = sample[mask].reshape(-1,22)\n",
    "    X_train_no_nan.append(sample_no_nan)\n",
    "    \n",
    "\n",
    "X_train_no_nan = np.vstack(X_train_no_nan)\n",
    "mean = np.mean(X_train_no_nan, axis=0)\n",
    "std = np.std(X_train_no_nan, axis=0)\n",
    "\n",
    "#print(mean, std)\n",
    "\n",
    "\n",
    "# Scale everything\n",
    "for i in range(X_train.shape[0]):\n",
    "    sample = X_train[i]\n",
    "    #print(sample.shape)\n",
    "    mask = ~np.isnan(sample)\n",
    "    sample_no_nan = sample[mask].reshape(-1,22)\n",
    "    scaled = (sample_no_nan - mean) / std\n",
    "    #print(scaled)\n",
    "    #print(scaled.shape)\n",
    "    X_train[i].ravel()[:len(scaled.ravel())] = scaled.ravel()\n",
    "    \n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05610578, -0.11313968, -0.13779364,  0.5992977 ,  0.30666848,\n",
       "        0.46251229,  0.08999458,  0.05210866,  0.02986489,  0.05501536,\n",
       "        0.07046579,  0.05096768, -0.0443975 , -0.1206937 ,  0.43741315,\n",
       "        0.39030944,  0.5483283 ,  0.27882825,  0.05666373,  0.22534062,\n",
       "        0.13895616,  0.26285182])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X_train_no_nan,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "df = pd.DataFrame(data, columns=['label', 'time_series'])\n",
    "seed = 0\n",
    "X = df['time_series']\n",
    "y = df['label']\n",
    "\n",
    "X = to_time_series_dataset(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.222222222222222, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "doing parameters search...: 100%|██████████| 9/9 [3:11:05<00:00, 1273.89s/it]  \n",
      "doing parameters search...: 100%|██████████| 9/9 [4:04:48<00:00, 1632.01s/it]  \n",
      "doing parameters search...: 100%|██████████| 9/9 [4:05:51<00:00, 1639.10s/it]  \n",
      "doing parameters search...: 100%|██████████| 9/9 [4:00:34<00:00, 1603.83s/it]  \n",
      "doing parameters search...: 100%|██████████| 9/9 [4:07:08<00:00, 1647.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best combination! (1, 10) w. accuracy of 0.6962406015037594.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tslearn.svm import TimeSeriesSVC\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_folds = 5\n",
    "skf = sk.model_selection.StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "params = [[1e-4, 1e-2, 1], [1e-1, 1, 10]]\n",
    "params_comb = list(itertools.product(*params))\n",
    "\n",
    "acc_scores = np.zeros(len(params_comb))\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_cv = X_train[train_index]\n",
    "    y_train_cv = y_train.iloc[train_index]\n",
    "    X_val_cv = X_train[val_index]\n",
    "    y_val_cv = y_train.iloc[val_index]\n",
    "    \n",
    "    mean_ary, std_ary = base.compute_mean_and_std(X_train_cv)\n",
    "\n",
    "    # Scale X_train_cv \n",
    "    X_train_cv = base.apply_z_standardization(X_train_cv, mean_ary, std_ary)\n",
    "    # Scale X_test_cv\n",
    "    X_val_cv = base.apply_z_standardization(X_val_cv, mean_ary, std_ary)\n",
    "    \n",
    "    for i, params in enumerate(tqdm(params_comb, desc='doing parameters search...')):\n",
    "        clf = TimeSeriesSVC(C=params[0], gamma=params[1], kernel=\"gak\", max_iter=1000)\n",
    "        clf.fit(X_train_cv, y_train_cv)\n",
    "        predictions = clf.predict(X_val_cv)\n",
    "        res = accuracy_score(y_val_cv, predictions)\n",
    "        acc_scores[i] += res\n",
    "acc_scores = acc_scores / n_folds\n",
    "best_idx = np.argmax(acc_scores)    \n",
    "print(f'Found best combination! {params_comb[best_idx]} w. accuracy of {acc_scores[best_idx]}.')\n",
    "best_comb = params_comb[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached an accuracy of 0.6859649122807018.\n"
     ]
    }
   ],
   "source": [
    "mean_ary, std_ary = base.compute_mean_and_std(X_train)\n",
    "\n",
    "# Scale X_train_cv \n",
    "X_train = base.apply_z_standardization(X_train, mean_ary, std_ary)\n",
    "# Scale X_test_cv\n",
    "X_test = base.apply_z_standardization(X_test, mean_ary, std_ary)\n",
    "\n",
    "clf = TimeSeriesSVC(C=best_comb[0], gamma=best_comb[1], kernel=\"gak\")\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "res = accuracy_score(y_test, predictions)\n",
    "print(f'Reached an accuracy of {res}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "391ddcc66a8b67209ee4ca14a5da0cf1073041a687facbd61882e6753a3822ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
